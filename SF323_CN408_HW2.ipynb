{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXJLPRjPSVPZPfvYhWpNW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongsa-nut/SF323_CN408_AIEngineer/blob/main/SF323_CN408_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW 2 (5 points)"
      ],
      "metadata": {
        "id": "3lLqjjYuNJgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Count Tokens (1 point)\n",
        "\n",
        "Count the number of tokens using [gpt-4o tokenizer](https://platform.openai.com/tokenizer) (you can use the web or the code) of the following four prompts:\n",
        "\n",
        "1. The old man sat on the park bench, feeding pigeons and lost in thought. As the sun began to set, he smiled, realizing that sometimes the simplest moments are the most precious.\n",
        "\n",
        "2. ชายชรานั่งอยู่บนม้านั่งในสวนสาธารณะ ให้อาหารนกพิราบและจมอยู่ในภวังค์ความคิด เม่ือดวงอาทิตย์เรี่มตกดิน เขายิ้ม ตระหนักว่าบางครั้งช่วงเวลาที่เรียบง่ายที่สุดกลับมีค่าที่สุด\n",
        "\n",
        "3. 老人は公園のベンチに座り、鳩に餌をやりながら物思いにふけっていた。日が沈み始めると、彼は微笑み、時として最も単純な瞬間が最も貴重であることに気づいた。\n",
        "\n",
        "4. 9.11 > 9.9"
      ],
      "metadata": {
        "id": "ROi0QF4-XpUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3.\n",
        "\n",
        "4."
      ],
      "metadata": {
        "id": "BGRsu2X1oNqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Word Embedding: Closet words (1 point)\n",
        "\n",
        "For this question, your job is find the closest words of the following words in the vector space of Word2Vec embedding.\n",
        "\n",
        "1) cat\n",
        "\n",
        "2) King\n",
        "\n",
        "3) teaching\n",
        "\n",
        "4) learning\n",
        "\n",
        "The code is provided below."
      ],
      "metadata": {
        "id": "Ue7A7YVJZEAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First install the library spacy\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9BeQZpENZJ9W",
        "outputId": "d13be7c1-e349-4da6-b04f-cf6be8dea165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-trained Word2Vec embeddings (~1.6gb)\n",
        "model = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5MJVMEiaXEX",
        "outputId": "e5813379-9bdc-4392-8a83-30c3835e0720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of usage\n",
        "word = 'Merry'\n",
        "model.similar_by_word(word) # It will return top 10 closest words. ['word','cosine similarity']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-55vrGrgLLi",
        "outputId": "748fa543-0585-4425-8045-42d6064542e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Shavaun', 0.49784329533576965),\n",
              " ('Apple_Dumpling', 0.4907097816467285),\n",
              " ('Merry_Merry', 0.4760850667953491),\n",
              " ('Christma', 0.4625037908554077),\n",
              " ('Gravener', 0.4579834043979645),\n",
              " ('OPEN_RESTRICTED_1', 0.45711594820022583),\n",
              " ('Reindeers', 0.4541266858577728),\n",
              " ('Rub_Dub_Dub', 0.4538874328136444),\n",
              " ('Fancy_Nancy_Splendiferous', 0.4518665373325348),\n",
              " ('XMas', 0.45152536034584045)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3.\n",
        "\n",
        "4."
      ],
      "metadata": {
        "id": "l-GLbStuojvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Sentence Embedding: Closest sentences (1 points)\n",
        "\n",
        "For this question, you will be using cohere API to explore Sentence Embedding. The idea is still the same, similar sentences will be closer in the embedding space.\n",
        "\n",
        "To run the code below, the first step you must obtain cohere API trial (free) key from their [website](https://dashboard.cohere.ai/welcome/register).\n",
        "\n",
        "![key_trial.png](https://drive.google.com/uc?export=view&id=1rdMaMdO5S7eaktN0qwodhgQd3auuZ6gi)\n",
        "\n",
        "* Note: Be careful about rate limit for free key. 5 calls per minute."
      ],
      "metadata": {
        "id": "GDiQhzguZPkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "Or293PTsQbY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cohere\n",
        "co = cohere.Client(\"YOUR_COHERE_API_KEY\") # Your Cohere API key"
      ],
      "metadata": {
        "id": "Au3eOYBsQXdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our documents. It is just a list of strings (sentences)\n",
        "# (Taken from https://github.com/anthropics/anthropic-cookbook/blob/main/third_party/VoyageAI/how_to_create_embeddings.md)\n",
        "documents = [\n",
        "    \"The Mediterranean diet emphasizes fish, olive oil, and vegetables, believed to reduce chronic diseases.\",\n",
        "    \"Photosynthesis in plants converts light energy into glucose and produces essential oxygen.\",\n",
        "    \"20th-century innovations, from radios to smartphones, centered on electronic advancements.\",\n",
        "    \"Rivers provide water, irrigation, and habitat for aquatic species, vital for ecosystems.\",\n",
        "    \"Apple’s conference call to discuss fourth fiscal quarter results and business updates is scheduled for Thursday, November 2, 2023 at 2:00 p.m. PT / 5:00 p.m. ET.\",\n",
        "    \"Shakespeare's works, like 'Hamlet' and 'A Midsummer Night's Dream,' endure in literature.\"\n",
        "]\n",
        "\n",
        "# Embedded (More info: https://docs.cohere.com/reference/embed?ref=cohere-ai.ghost.io )\n",
        "response = co.embed(\n",
        "    texts=documents,\n",
        "    model='embed-english-v3.0',\n",
        "    input_type='search_document'\n",
        ")\n",
        "\n",
        "embeddings = response.embeddings\n",
        "\n",
        "print(f\"The dimension of the embedding =  {len(embeddings[0])}\")\n",
        "\n",
        "print(f\"\\nEmbedding for sentence 1: {embeddings[0]}\")\n",
        "print(f\"Embedding for sentence 2: {embeddings[1]}\")\n",
        "print(f\"Embedding for sentence 3: {embeddings[0]}\")\n",
        "\n",
        "# To calculate similarity we can use dot product (same as cosine similarity when vectors have been normarlized to 1.)\n",
        "print(\"\\nSimilarity between sentences 1 and 2:\", np.dot(embeddings[0], embeddings[1]))\n",
        "print(\"Similarity between sentences 1 and 3:\", np.dot(embeddings[0], embeddings[2]))\n",
        "print(\"Similarity between sentences 2 and 3:\", np.dot(embeddings[0], embeddings[3]))"
      ],
      "metadata": {
        "id": "Mb0NxJ1_ZUaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to find the closest document\n",
        "def closest_document(sentence, documents, model='embed-english-v3.0'):\n",
        "    # Merge into one so that it would only use one call to API.\n",
        "    documents = documents.copy() + [sentence]\n",
        "    response = co.embed(\n",
        "        texts=documents,\n",
        "        model=model,\n",
        "        input_type='search_document'\n",
        "    )\n",
        "    embeddings = response.embeddings\n",
        "    # Calculate dot products of the sentence and every document\n",
        "    similarities = [np.dot(embeddings[i], embeddings[-1]) for i in range(len(embeddings)-1)]\n",
        "    # print similarities and index\n",
        "    for i, sim in enumerate(similarities):\n",
        "        print(f\"Similarity between sentence {i+1} and the new sentence: {sim}\")\n",
        "\n",
        "    max_index = np.argmax(similarities)\n",
        "    return max_index, documents[max_index]"
      ],
      "metadata": {
        "id": "JRfYWN8xX5ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A similar sentence to the first sentence\n",
        "test_sentence = \"Focusing on seafood, olive oil, and plant-based foods, the Mediterranean eating pattern is thought to lower the risk of long-term health conditions.\"\n",
        "\n",
        "index, sentence = closest_document(test_sentence, documents)\n",
        "print(f\"The closest sentence to '{test_sentence}' is '{sentence}' at index {index}.\")"
      ],
      "metadata": {
        "id": "JVm2o2ws03Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.1** Come up with a sentence that is closest to the fifth sentence (```\"Apple’s conference call to discuss fourth fiscal quarter results and business updates is scheduled for Thursday, November 2, 2023 at 2:00 p.m. PT / 5:00 p.m. ET.\"```)"
      ],
      "metadata": {
        "id": "zaGTiRP-zvpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_sentence = \"\" #Your sentence here\n",
        "\n",
        "index, sentence = closest_document(your_sentence, documents)\n",
        "print(f\"The closest sentence to '{your_sentence}' is '{sentence}' at index {index}.\")"
      ],
      "metadata": {
        "id": "Yb9E3K-8R2Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.2** Come up with a sentence that is closest to the sixth sentence (`\"Shakespeare's works, like 'Hamlet' and 'A Midsummer Night's Dream,' endure in literature.\"`).\n",
        "\n",
        "Note your sentence must not contain the word 'Shakespeare'"
      ],
      "metadata": {
        "id": "4M3galSwz3Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_sentence = \"\" #Your sentence here\n",
        "\n",
        "index, sentence = closest_document(your_sentence, documents)\n",
        "print(f\"The closest sentence to '{your_sentence}' is '{sentence}' at index {index}.\")"
      ],
      "metadata": {
        "id": "gMRvWX9mYHl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.3** Come up with a sentence in \"Thai\" that is closest to the second sentence. (`\"Photosynthesis in plants converts light energy into glucose and produces essential oxygen.\"`)"
      ],
      "metadata": {
        "id": "F0qbmDYB0T_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_sentence = \"\" #Your sentence here\n",
        "\n",
        "index, sentence = closest_document(your_sentence, documents, 'embed-multilingual-v3.0')\n",
        "print(f\"The closest sentence to '{your_sentence}' is '{sentence}' at index {index}.\")"
      ],
      "metadata": {
        "id": "TeLxYCteW8sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.4** Come up with a sentence in \"Japanese\" that is closest to the first sentence. (`\"The Mediterranean diet emphasizes fish, olive oil, and vegetables, believed to reduce chronic diseases.\"`)\n"
      ],
      "metadata": {
        "id": "v0YcOXPK0f7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "your_sentence = \"\" #Your sentence here\n",
        "\n",
        "index, sentence = closest_document(your_sentence, documents, 'embed-multilingual-v3.0')\n",
        "print(f\"The closest sentence to '{your_sentence}' is '{sentence}' at index {index}.\")"
      ],
      "metadata": {
        "id": "qf1tkXmqYtWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Multi turn chatbot (1 point)\n",
        "\n",
        "For this question, your task is to implement a simple multi-turn chatbot by filling in the code **using provided helper functions**\n",
        "\n",
        "We will be using `gemini-2.5-flash-lite` for this homework (See available models [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions)).\n",
        "\n",
        "[Documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/start/openai) for using Gemini with OpenAI library"
      ],
      "metadata": {
        "id": "0cm3v4Skov8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenRouter"
      ],
      "metadata": {
        "id": "uN5f68byDY_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=userdata.get('openrouter'),\n",
        ")"
      ],
      "metadata": {
        "id": "bd4s5QepDeNA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YoRVFAXvDUsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that you successfully connect to vertex\n",
        "response = client.chat.completions.create(\n",
        "  model=\"google/gemini-2.5-flash-lite\",\n",
        "  messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "      {\"role\": \"user\", \"content\": \"Hello, test\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "t-v0KFaKFR9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"google/gemini-2.5-flash-lite\"\n",
        "\n",
        "# Helper functions\n",
        "def add_user_message(messages, text):\n",
        "    user_message = {\"role\": \"user\", \"content\": text}\n",
        "    messages.append(user_message)\n",
        "\n",
        "def add_assistant_message(messages, text):\n",
        "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
        "    messages.append(assistant_message)\n",
        "\n",
        "def chat(messages, temperature=0.7):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=10000,\n",
        "        temperature = temperature\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "KxXSVMbSo9YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use **provided helper functions** to implement a multi turn chatbot\n",
        "\n",
        "**Note**: Test your program so I can check that it works!"
      ],
      "metadata": {
        "id": "sktmt5ER7pa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with an empty message list\n",
        "messages = []\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input('User: ')\n",
        "\n",
        "    # If user types 'quit', break out of the loop\n",
        "    if user_input == 'quit':\n",
        "        break\n",
        "\n",
        "    # Add user input to the list of messages with the helper function\n",
        "    _______________________________________\n",
        "\n",
        "    # Call the model with the helper function\n",
        "    _______________________________________\n",
        "\n",
        "    # Add model's response to the list of messages with the helper function\n",
        "    _______________________________________\n",
        "\n",
        "    # Print the generated text\n",
        "    _______________________________________"
      ],
      "metadata": {
        "id": "AbFVRVwEpAeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Prompt Engineering Basic (1 points)"
      ],
      "metadata": {
        "id": "rGEnhvNvpPxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function. DO NOT CHANGE. (Must run the earlier cell first)\n",
        "# Temperature is set to 0 so that the answer will be the same.\n",
        "def get_response(user_prompt, system_prompt=\"\",temperature=0):\n",
        "  temp_messages =[\n",
        "        {'role':'system','content':system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "  ]\n",
        "\n",
        "  return chat(temp_messages, temperature = 0)\n",
        "\n",
        "# Testing if your api key is working\n",
        "print(get_response(\"Hello\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkkHgF6_pYvd",
        "outputId": "3e995706-e875-4c97-ab8c-84a8caa50231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.1** Get the model to count to three"
      ],
      "metadata": {
        "id": "RZC0pFifreNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXejM879rRKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7078080-b57b-4e8e-9187-da915af91f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One, two, three.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\" #Fill in your prompt here\n",
        "print(get_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.2** Modify the system prompt to make **the model respond like it's a 3 year old child**."
      ],
      "metadata": {
        "id": "LKGmqYFYvZCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\" #Fill in your prompt here\n",
        "prompt = \"How big is the sky?\"\n",
        "print(get_response(prompt, system_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK7GMvKMvYxT",
        "outputId": "5894b144-116f-43a2-db43-cfbdcc7c6894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The \"sky\" is a fascinating concept because its \"size\" depends entirely on how you define it! Here are a few ways to think about it:\n",
            "\n",
            "1.  **The Earth's Atmosphere (The Sky We Breathe and See Clouds In):**\n",
            "    *   This is the layer of gases surrounding our planet. Most of what we consider \"sky\" in our daily lives (weather, clouds, blue color) happens in the lowest layers.\n",
            "    *   **Troposphere:** Where most weather occurs, extends up to about 8-15 km (5-9 miles) high.\n",
            "    *   **Stratosphere:** Contains the ozone layer, extends up to about 50 km (31 miles).\n",
            "    *   **Mesosphere:** Extends up to about 85 km (53 miles).\n",
            "    *   **Thermosphere:** Where the aurora occur, extends up to about 600 km (370 miles) or more.\n",
            "    *   **Exosphere:** The outermost layer, gradually thinning out into space, extending up to about 10,000 km (6,200 miles).\n",
            "    *   **The Kármán Line:** This is an internationally recognized boundary at **100 km (62 miles)** above Earth's mean sea level, often considered the edge of space. So, in this sense, the \"sky\" (atmosphere) is a relatively thin shell around the Earth.\n",
            "\n",
            "2.  **The Visible Sky (The Dome Above Us):**\n",
            "    *   From any point on Earth, the sky appears as a vast dome or hemisphere that meets the horizon.\n",
            "    *   Its \"size\" in this sense is limited by your line of sight and the curvature of the Earth. If you're standing on a flat plain, you can see for about 4.8 km (3 miles) to the horizon. So, the *visible* dome above you is effectively that wide.\n",
            "    *   Of course, if you go up in an airplane or a mountain, your horizon expands, and the visible sky appears \"bigger.\"\n",
            "\n",
            "3.  **Outer Space (The Night Sky):**\n",
            "    *   When we look up at night, we're looking beyond our atmosphere into the vastness of space.\n",
            "    *   **The Observable Universe:** This is the part of the universe that we can theoretically see from Earth, given the age of the universe and the speed of light. It's estimated to be about **93 billion light-years in diameter**. A light-year is the distance light travels in one year (about 9.46 trillion kilometers or 5.88 trillion miles). This is an incomprehensibly vast scale.\n",
            "    *   **The Universe as a Whole:** We don't know if the entire universe is finite or infinite, but it's certainly much larger than just the observable part.\n",
            "\n",
            "**In summary:**\n",
            "\n",
            "*   The \"sky\" as our **atmosphere** is a relatively thin shell, with its \"edge\" often defined at 100 km (62 miles).\n",
            "*   The \"sky\" as the **visible dome** above us is limited by our horizon, typically a few miles in radius.\n",
            "*   The \"sky\" as **outer space** is unimaginably vast, with the observable part alone spanning 93 billion light-years.\n",
            "\n",
            "So, the sky is both a thin, life-sustaining blanket and an infinite, awe-inspiring expanse, depending on your perspective!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.3** Adapt the system prompt to make the model output its answer in Thai.\n"
      ],
      "metadata": {
        "id": "Svrvn_KvwDBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\" #Fill in your prompt here\n",
        "prompt = \"Hello, how are you?\"\n",
        "print(get_response(prompt, system_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9sp5x28wIp1",
        "outputId": "1e33bc1e-673c-4840-81f0-9434be9c3139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm functioning perfectly and ready to assist you. Thank you for asking!\n",
            "\n",
            "How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.4** Modify the basketball player prompt so that Claude doesn't equivocate at all and responds with **ONLY the name of one specific player**, with no other words or punctuation.\n"
      ],
      "metadata": {
        "id": "hR1W2RtewRzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Who is the best basketball player of all time?\"\n",
        "print(get_response(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co3ty733weDa",
        "outputId": "f52e4c51-cf91-43fc-c159-9de79270d1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's one of the most debated questions in sports, and there's no single definitive answer! It largely depends on what criteria you value most.\n",
            "\n",
            "However, the two players most consistently at the center of the \"Greatest Of All Time\" (GOAT) debate are:\n",
            "\n",
            "1.  **Michael Jordan:**\n",
            "    *   **Arguments for:** Unblemished 6-0 record in the NBA Finals, 6 Finals MVPs, 5 regular season MVPs, 10 scoring titles, Defensive Player of the Year award, unparalleled clutch performance, incredible competitive drive, and global cultural impact. Many believe he was the most dominant player in his era and had a perfect \"peak.\"\n",
            "    *   **Arguments against:** Played in a different era with different rules (e.g., hand-checking), shorter career at the absolute elite level compared to some others.\n",
            "\n",
            "2.  **LeBron James:**\n",
            "    *   **Arguments for:** Unmatched longevity and sustained excellence (still playing at an elite level in his 20th+ season), all-time leading scorer in NBA history, 4 NBA championships with 3 different franchises, 4 Finals MVPs, 4 regular season MVPs, incredible all-around game (scoring, passing, rebounding, defense), and versatility to play all five positions.\n",
            "    *   **Arguments against:** Has lost more NBA Finals (4-6 record) than Jordan, some argue he had more \"super teams\" built around him.\n",
            "\n",
            "**Other players often mentioned in the conversation for their unique contributions and dominance:**\n",
            "\n",
            "*   **Kareem Abdul-Jabbar:** All-time leading scorer for decades, 6 NBA championships, 6 MVPs, revolutionary \"skyhook.\"\n",
            "*   **Bill Russell:** 11 NBA championships in 13 seasons (unmatched winning), defensive anchor, pioneer.\n",
            "*   **Magic Johnson:** Revolutionary point guard, 5 NBA championships, 3 MVPs, 3 Finals MVPs, incredible passer and versatile player.\n",
            "*   **Wilt Chamberlain:** Unparalleled statistical dominance (100-point game, 50 PPG season), but \"only\" 2 championships.\n",
            "\n",
            "**Ultimately, who you consider the \"best\" often comes down to:**\n",
            "\n",
            "*   **Championships:** Do you prioritize winning above all else?\n",
            "*   **Individual Accolades:** MVPs, scoring titles, defensive awards.\n",
            "*   **Statistical Dominance:** Raw numbers and efficiency.\n",
            "*   **Impact on the Game:** How did they change basketball?\n",
            "*   **Longevity vs. Peak:** Do you value a longer career of excellence or a shorter, more dominant peak?\n",
            "*   **Clutch Performance:** Who delivered when it mattered most?\n",
            "\n",
            "It's a fantastic debate with valid points for multiple players!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.5** Modify the prompt so that Gemini responds with as long a response as you can muster. Gemini's response should be over 800 words.\n"
      ],
      "metadata": {
        "id": "T1YWhAU7wsEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write me a short story?\"\n",
        "response = get_response(prompt)\n",
        "print(f\"Number of words = {len(response.split())}\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "NWds_MrXw5xH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55282c3e-547e-4610-ca2f-0eb7b28951b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words = 472\n",
            "Elara loved the quiet hum of the old city library. It was a place of hushed reverence, where the scent of aged paper and dust motes dancing in sunbeams felt like a comforting embrace. She wasn't looking for anything in particular today, just wandering the labyrinthine aisles, her fingers trailing over the spines of forgotten tales.\n",
            "\n",
            "Deep in a rarely visited section, tucked behind a row of weighty tomes on ancient cartography, she found it. It wasn't grand or ornate, just a slim, unassuming book with a cover of smooth, dark wood, no title, no author. It felt cool to the touch, almost alive.\n",
            "\n",
            "Curiosity piqued, Elara pulled it free and settled into a worn armchair by a tall window. She opened the book. The pages were utterly blank. Not yellowed or stained, but a pristine, almost luminous white. Disappointment pricked at her, but as she was about to close it, a faint shimmer, like heat haze over a summer road, rippled across the first page.\n",
            "\n",
            "Then, slowly, ink began to bloom. Not words, not drawings, but vivid, moving images.\n",
            "\n",
            "She saw a bustling market in a city of spires she’d never known, the air thick with the scent of exotic spices and the chatter of a hundred languages. She felt the warmth of the sun on her face, heard the distant call of a street vendor.\n",
            "\n",
            "The page shifted. Now, she was standing on the silent, snow-dusted peaks of a mountain range, the wind biting at her cheeks, the vast, star-dusted sky stretching endlessly above. She felt a profound sense of insignificance, yet also an exhilarating freedom.\n",
            "\n",
            "Another shift. A quiet, sun-dappled forest, where ancient trees whispered secrets to the breeze. She saw a tiny, iridescent beetle crawling on a mossy stone, and for a moment, she *was* that beetle, experiencing the world from its miniature perspective.\n",
            "\n",
            "Elara didn't just see these things; she *felt* them. The book wasn't showing her stories; it was showing her *experiences*, moments of pure, unadulterated existence from places and perspectives she could never have imagined. It was a whisper of the infinite possibilities of the world, a glimpse into the vast tapestry of life.\n",
            "\n",
            "Finally, the images faded, the pages returning to their pristine blankness. Elara closed the book, her heart thrumming with a quiet awe. She placed it back on the shelf, nestled amongst its dusty brethren, knowing it was meant for another curious soul to find.\n",
            "\n",
            "But Elara wasn't the same. The quiet hum of the library now seemed to sing with a new melody. The world outside, which had often felt small and predictable, now sparkled with untold stories, unseen wonders, and the promise of a thousand new experiences waiting just beyond the next page. She walked out into the city, her steps lighter, a quiet, knowing smile playing on her lips.\n"
          ]
        }
      ]
    }
  ]
}